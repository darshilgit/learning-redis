# Redis Deep Dive - Technical Architecture & Internals

**A comprehensive technical guide to understanding Redis from the inside out.**

---

## ğŸ“‹ Table of Contents

1. [Redis Architecture](#redis-architecture)
2. [Memory Management & Eviction](#memory-management--eviction)
3. [Persistence Strategies](#persistence-strategies)
4. [Replication](#replication)
5. [High Availability with Sentinel](#high-availability-with-sentinel)
6. [Horizontal Scaling with Cluster](#horizontal-scaling-with-cluster)
7. [Performance Characteristics](#performance-characteristics)
8. [Production Considerations](#production-considerations)

---

## ğŸ—ï¸ Redis Architecture

### Core Design Principles

Redis is built on three fundamental principles that make it unique:

#### 1. In-Memory Data Store

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Application Layer           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Redis Protocol
               â”‚ (RESP - Redis Serialization Protocol)
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Redis Server                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     Command Processor         â”‚  â”‚
â”‚  â”‚   (Single-threaded event loop)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â†“                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      Data Structures          â”‚  â”‚
â”‚  â”‚  â€¢ Strings  â€¢ Sorted Sets     â”‚  â”‚
â”‚  â”‚  â€¢ Hashes   â€¢ Streams         â”‚  â”‚
â”‚  â”‚  â€¢ Lists    â€¢ Bitmaps         â”‚  â”‚
â”‚  â”‚  â€¢ Sets     â€¢ HyperLogLog     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â†“                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      Memory (RAM)             â”‚  â”‚
â”‚  â”‚   Everything lives here!      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â†“ (Optional)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Persistence Layer          â”‚  â”‚
â”‚  â”‚    â€¢ RDB (snapshots)          â”‚  â”‚
â”‚  â”‚    â€¢ AOF (append-only log)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Disk   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why In-Memory?**
- **Latency:** RAM access is ~100,000x faster than disk
- **Throughput:** Can handle 100k+ operations/second per node
- **Simple:** No complex query optimizer needed

**Trade-off:** Data must fit in RAM (but that's the point!)

#### 2. Single-Threaded Event Loop

```
Redis Process:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Main Thread (Event Loop)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  while(true) {                   â”‚  â”‚
â”‚  â”‚    event = wait_for_event()      â”‚  â”‚
â”‚  â”‚    process_command(event)        â”‚  â”‚
â”‚  â”‚    send_response(event)          â”‚  â”‚
â”‚  â”‚  }                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Background Threads (Redis 4.0+):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â€¢ Lazy deletion thread                â”‚
â”‚  â€¢ AOF rewrite thread                  â”‚
â”‚  â€¢ RDB save thread                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why Single-Threaded?**
- **No locks:** Simplifies implementation massively
- **Predictable:** No race conditions, no deadlocks
- **Fast:** No context switching overhead
- **Atomic:** Every command is naturally atomic

**Common Misconception:** "Single-threaded = slow"
- **Reality:** Redis processes commands at RAM speed, not CPU speed
- Network I/O is the bottleneck, not processing

**Note:** Redis 6.0+ uses multi-threading for I/O, but command processing is still single-threaded.

#### 3. Rich Data Structures

Unlike simple key-value stores, Redis implements complex data structures **in the server**:

```c
// Redis doesn't just store bytes - it understands data structures!

// String: Simple value
GET user:1000:name  â†’ "Alice"

// Hash: Like a struct
HGETALL user:1000
1) "name"
2) "Alice"
3) "email"
4) "alice@example.com"
5) "age"
6) "30"

// Sorted Set: Maintained in sorted order automatically
ZADD leaderboard 1500 "player1"
ZREVRANGE leaderboard 0 9  â†’ Top 10 automatically sorted!
```

**Why This Matters:**
- Operations are **server-side** (no data transfer for complex operations)
- Atomic guarantees on complex operations
- Optimized C implementations (fast!)

### Internal Data Structure Implementations

Redis uses different encodings based on size for memory efficiency:

#### Strings

```
Small strings (<= 44 bytes):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Header  â”‚  Data (inline)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
16 bytes    up to 44 bytes

Large strings:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Header  â”‚â”€â”€â”€â”€â”€â”€â”€â†’â”‚   Data   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   (ptr)           (allocated)
```

#### Lists

Implemented as **quicklists** (combination of linked list + ziplist):

```
Small lists (< 512 entries):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ziplist (compressed array)     â”‚
â”‚  [entry1][entry2][entry3]...    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Large lists:
â”Œâ”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”
â”‚Nodeâ”‚â”€â”€â”€â†’â”‚Nodeâ”‚â”€â”€â”€â†’â”‚Nodeâ”‚
â””â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”˜
  â†“         â†“         â†“
Ziplist   Ziplist   Ziplist
```

#### Hashes

```
Small hashes (< 512 fields):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ziplist: [k1][v1][k2][v2]...   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Large hashes:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Hash Table          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ k1   â”‚ ptrâ†’v1   â”‚   â”‚
â”‚  â”‚ k2   â”‚ ptrâ†’v2   â”‚   â”‚
â”‚  â”‚ ...  â”‚ ...      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Sorted Sets

Implemented as **skiplist + hash table**:

```
Hash Table (O(1) member lookup):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ member1 â†’ score1     â”‚
â”‚ member2 â†’ score2     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Skiplist (O(log N) range queries):
Level 3: [head]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’[member3]
Level 2: [head]â”€â”€â”€â”€â”€â”€â”€â”€â†’[member2]â”€â”€â”€â”€â”€â”€â”€â”€â†’[member3]
Level 1: [head]â†’[member1]â†’[member2]â†’[member3]
          score:0  score:100  score:200  score:300
```

**Why Skiplist?**
- O(log N) insertion, deletion, range queries
- Simpler than balanced trees
- Memory-efficient
- Great for range operations (ZRANGE, ZRANGEBYSCORE)

---

## ğŸ§  Memory Management & Eviction

### Memory Allocation

Redis uses **jemalloc** (or libc malloc) with these characteristics:

```
Memory Layout:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Server Overhead (2-5 MB)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Client Buffers (per client)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Replication Buffer (if replica)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AOF Rewrite Buffer (if AOF)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Structures (your data!)          â”‚
â”‚  â€¢ Keys                                â”‚
â”‚  â€¢ Values                              â”‚
â”‚  â€¢ Metadata (TTL, encoding, etc.)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Overhead per key: ~100 bytes
```

**Memory Calculation Example:**
```
1 million strings (avg 1KB each):
â€¢ Data: 1M * 1KB = 1 GB
â€¢ Keys: 1M * 100 bytes = 100 MB
â€¢ Overhead: ~200 MB
â€¢ Total: ~1.3 GB
```

### Eviction Policies

When Redis reaches `maxmemory`, it must evict keys. You configure this with `maxmemory-policy`:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EVICTION POLICIES                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  noeviction (default)                â”‚
â”‚  â€¢ Return errors when memory full    â”‚
â”‚  â€¢ Reads work, writes fail           â”‚
â”‚  â€¢ Use when: Data must not be lost   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  volatile-lru                        â”‚
â”‚  â€¢ Evict least recently used         â”‚
â”‚  â€¢ Only keys WITH expire set         â”‚
â”‚  â€¢ Use when: Cache with TTLs         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  allkeys-lru                         â”‚
â”‚  â€¢ Evict least recently used         â”‚
â”‚  â€¢ ANY key (even without TTL)        â”‚
â”‚  â€¢ Use when: Pure cache              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  volatile-lfu                        â”‚
â”‚  â€¢ Evict least frequently used       â”‚
â”‚  â€¢ Only keys WITH expire set         â”‚
â”‚  â€¢ Use when: Frequency matters       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  allkeys-lfu                         â”‚
â”‚  â€¢ Evict least frequently used       â”‚
â”‚  â€¢ ANY key                           â”‚
â”‚  â€¢ Use when: Access patterns vary    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  volatile-random                     â”‚
â”‚  â€¢ Evict random key WITH expire      â”‚
â”‚  â€¢ Use when: No access pattern       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  allkeys-random                      â”‚
â”‚  â€¢ Evict random key                  â”‚
â”‚  â€¢ Use when: All keys equal          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  volatile-ttl                        â”‚
â”‚  â€¢ Evict keys expiring soon          â”‚
â”‚  â€¢ Use when: Respect expiration      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### LRU vs LFU: Which to Choose?

**LRU (Least Recently Used):**
```
Timeline: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
Key A:    âœ“(accessed)................
Key B:    ...................âœ“(accessed)
Key C:    .........âœ“(accessed).......

Memory full, need to evict:
â†’ Evict Key A (accessed longest time ago)
```

**Good for:** Time-based access patterns (recent items matter)

**LFU (Least Frequently Used):**
```
Access counts:
Key A: |||||||||| (10 accesses)
Key B: |||| (4 accesses)
Key C: |||||| (6 accesses)

Memory full, need to evict:
â†’ Evict Key B (least frequently used)
```

**Good for:** Popularity-based patterns (frequently accessed items matter)

#### Choosing a Policy

```
Decision Tree:

â”Œâ”€ Do you want errors when full? â”€â”
â”‚  YES â†’ noeviction               â”‚
â”‚  NO  â†’ Continue...              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ Using TTLs on all keys? â”€â”€â”€â”€â”€â”€â”
â”‚  YES â†’ volatile-* policies      â”‚
â”‚  NO  â†’ allkeys-* policies       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ Access pattern? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Recent matters    â†’ *-lru      â”‚
â”‚  Frequency matters â†’ *-lfu      â”‚
â”‚  No pattern        â†’ *-random   â”‚
â”‚  Respect TTL       â†’ volatile-ttl
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Most Common Choices:**
- **Cache:** `allkeys-lru` or `allkeys-lfu`
- **Session store:** `volatile-lru`
- **Database:** `noeviction` (never lose data!)

### Memory Optimization Tips

```bash
# 1. Use hashes for small objects (more efficient)
# Bad: 1000 keys
SET user:1:name "Alice"
SET user:1:email "alice@example.com"
# ... 998 more keys

# Good: 1 hash
HMSET user:1 name "Alice" email "alice@example.com" ...

# 2. Monitor memory usage
INFO memory

# 3. Find memory hogs
MEMORY USAGE keyname

# 4. Use smaller integers when possible
# Redis optimizes for integers < 10000

# 5. Compress large strings
# Use ZLIB/GZIP before storing if >1KB
```

---

## ğŸ’¾ Persistence Strategies

Redis is in-memory, but data can be persisted to disk. Two mechanisms:

### RDB (Redis Database) - Snapshots

**How it works:**

```
Time: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
      â†“           â†“           â†“
    Snapshot    Snapshot    Snapshot
      
Each snapshot:
1. Fork process (copy-on-write)
2. Child writes data to temp file
3. Rename temp file to dump.rdb
4. Parent continues serving requests

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Parent Process (Redis)             â”‚
â”‚  â€¢ Continues serving requests       â”‚
â”‚  â€¢ Modified pages copied (COW)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ fork()
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Child Process                      â”‚
â”‚  â€¢ Writes snapshot to disk          â”‚
â”‚  â€¢ Exits when done                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Configuration:**

```redis
# Save snapshot every 60 seconds if 1000+ keys changed
save 60 1000

# Save every 5 minutes if 100+ keys changed
save 300 100

# Save every 15 minutes if 1+ key changed
save 900 1

# Or disable automatic saves
save ""
```

**Pros:**
- âœ… Compact single file (easy backups)
- âœ… Fast recovery (single disk read)
- âœ… Minimal performance impact
- âœ… Good for disaster recovery
- âœ… Fork process means parent never blocks

**Cons:**
- âŒ Can lose data since last snapshot
- âŒ Fork can be slow with large dataset
- âŒ Uses extra memory during save (copy-on-write)

**Use when:**
- Losing 1-5 minutes of data is acceptable
- You have enough RAM for fork
- Fast recovery is important

### AOF (Append-Only File) - Transaction Log

**How it works:**

```
Every write command is logged:

Time: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
      SET k1 v1
                 INCR counter
                              DEL k2
                                     HSET user:1 name Alice

AOF file:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SET k1 v1                  â”‚
â”‚ INCR counter               â”‚
â”‚ DEL k2                     â”‚
â”‚ HSET user:1 name Alice     â”‚
â”‚ ...                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Recovery:
Replay all commands â†’ Full state restored
```

**Configuration:**

```redis
# Enable AOF
appendonly yes

# Fsync strategy:

# 1. Always - Safest, slowest
appendfsync always
# Every write waits for disk
# Slowest, but max durability

# 2. Every second - Default, balanced
appendfsync everysec
# Background thread fsyncs every second
# Can lose 1 second of data

# 3. No - Let OS decide, fastest
appendfsync no
# OS controls flushing (usually 30s)
# Fastest, least durable
```

**AOF Rewrite:**

AOF files grow over time, so Redis can rewrite them:

```
Original AOF:
INCR counter        â†’ counter = 1
INCR counter        â†’ counter = 2
INCR counter        â†’ counter = 3
SET name "Alice"
SET name "Bob"

Rewritten AOF:
SET counter 3
SET name "Bob"

Much smaller!
```

**Pros:**
- âœ… More durable (can lose only 1 second)
- âœ… Append-only (safe, no corruption)
- âœ… Can be read/edited (human-readable)
- âœ… Auto-rewrite keeps file size reasonable

**Cons:**
- âŒ Larger files than RDB
- âŒ Slower than RDB (depends on fsync)
- âŒ Slower recovery (replay all commands)

**Use when:**
- Data loss is unacceptable
- You can tolerate slower writes
- Recovery time is less critical

### Hybrid (RDB + AOF) - Best of Both

Redis 4.0+ supports hybrid persistence:

```
Persistence Timeline:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RDB snapshot at T0                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Full dataset    â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚         +                              â”‚
â”‚  AOF since T0                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  SET k1 v1       â”‚                  â”‚
â”‚  â”‚  INCR counter    â”‚                  â”‚
â”‚  â”‚  ...             â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Recovery:
1. Load RDB (fast)
2. Replay AOF commands since snapshot (small)
â†’ Best of both worlds!
```

**Configuration:**

```redis
# Enable both
save 60 1000
appendonly yes

# Use RDB format for AOF rewrites
aof-use-rdb-preamble yes
```

**Pros:**
- âœ… Fast recovery (RDB) + minimal data loss (AOF)
- âœ… Compact files
- âœ… Best durability/performance balance

**Cons:**
- âŒ More complex setup
- âŒ Uses more disk space

### Choosing a Persistence Strategy

```
Decision Tree:

Can you lose ANY data?
â”œâ”€ YES â†’ How much?
â”‚  â”œâ”€ 1-5 minutes â†’ RDB only
â”‚  â””â”€ < 1 second  â†’ AOF (everysec)
â”‚
â””â”€ NO â†’ AOF (always) or Hybrid

Performance critical?
â”œâ”€ YES â†’ RDB or AOF (everysec)
â””â”€ NO  â†’ AOF (always)

Large dataset (> 10GB)?
â”œâ”€ YES â†’ RDB or Hybrid
â””â”€ NO  â†’ Any

Fast recovery important?
â”œâ”€ YES â†’ RDB or Hybrid
â””â”€ NO  â†’ AOF is fine
```

**Common Patterns:**

| Use Case | Strategy | Why |
|----------|----------|-----|
| **Cache** | RDB or none | Data loss OK, can rebuild |
| **Session store** | RDB (frequent) | Some loss OK, fast recovery |
| **Analytics** | AOF (everysec) | Can't lose data, but 1s OK |
| **Financial** | AOF (always) | Zero data loss |
| **General** | Hybrid | Best balance |

---

## ğŸ”„ Replication

Redis supports master-replica (formerly master-slave) replication for:
- High availability
- Read scaling
- Data redundancy

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Master (R/W)                    â”‚
â”‚  â€¢ Accepts writes                               â”‚
â”‚  â€¢ Serves reads                                 â”‚
â”‚  â€¢ Replicates to replicas                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Replica 1    â”‚   â”‚  Replica 2    â”‚
â”‚  (read-only)  â”‚   â”‚  (read-only)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How Replication Works

```
Initial Sync (Full Resync):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Master                          Replica
  â”‚                              â”‚
  â”‚â†â”€â”€â”€â”€â”€â”€PSYNC ? -1â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ 1. Replica: "Sync please"
  â”‚                              â”‚
  â”‚â”€â”€â”€â”€â”€FULLRESYNC <runid> <offset>â†’ 2. Master: "Do full sync"
  â”‚                              â”‚
  â”œâ”€ Fork & save RDB            â”‚
  â”œâ”€ Buffer new commands         â”‚
  â”‚                              â”‚
  â”‚â”€â”€â”€â”€â”€RDB fileâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚ 3. Send snapshot
  â”‚                              â”‚
  â”‚                              â”œâ”€ Load RDB
  â”‚                              â”‚
  â”‚â”€â”€â”€â”€â”€Buffered commandsâ”€â”€â”€â”€â”€â”€â”€â†’â”‚ 4. Send buffered writes
  â”‚                              â”‚
  â”‚â”€â”€â”€â”€â”€Stream commandsâ”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚ 5. Ongoing replication
  â”‚                              â”‚

Ongoing Replication:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Client           Master           Replica
  â”‚                â”‚                â”‚
  â”‚â”€â”€SET k1 v1â”€â”€â”€â”€â†’â”‚                â”‚
  â”‚                â”œâ”€â”€SET k1 v1â”€â”€â”€â”€â†’â”‚ (async)
  â”‚â†â”€OKâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚
  â”‚                â”‚                â”œâ”€Apply
  â”‚                â”‚                â”‚
```

**Key Characteristics:**

1. **Asynchronous:** Master doesn't wait for replicas (eventual consistency)
2. **Non-blocking:** Replicas can serve stale data during sync
3. **One direction:** Replicas are read-only
4. **Cascading:** Replicas can have sub-replicas

### Partial Resync (Redis 2.8+)

If replica disconnects briefly, it can partial resync:

```
Master maintains replication backlog:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Circular buffer (1MB default)       â”‚
â”‚  [cmd][cmd][cmd][cmd][cmd]...        â”‚
â”‚         â†‘                            â”‚
â”‚      offset = 1234                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Replica disconnects at offset 1000
Reconnects and says: "PSYNC <runid> 1000"

If 1000 is still in backlog:
â†’ Master sends commands since offset 1000
â†’ Fast catchup!

If 1000 is not in backlog:
â†’ Full resync needed
```

### Configuration

**On Replica:**

```redis
# Redis 5.0+
replicaof <master-ip> <master-port>

# Or: Redis < 5.0
slaveof <master-ip> <master-port>

# If master has password
masterauth <password>

# Allow reads from replica during sync?
replica-serve-stale-data yes

# Make replica read-only (recommended)
replica-read-only yes
```

**On Master:**

```redis
# Optional: Require password
requirepass <password>

# Min replicas for writes (safety)
min-replicas-to-write 1
min-replicas-max-lag 10
# "Only accept writes if >= 1 replica with lag < 10s"
```

### Replication Lag

Monitor with `INFO replication`:

```bash
redis-cli INFO replication

# Master shows:
role:master
connected_slaves:2
slave0:ip=10.0.1.2,port=6379,state=online,offset=1234,lag=0
slave1:ip=10.0.1.3,port=6379,state=online,offset=1230,lag=1

# Replica shows:
role:slave
master_host:10.0.1.1
master_port:6379
master_link_status:up
master_last_io_seconds_ago:0
master_sync_in_progress:0
```

**Lag = Time since last communication with master**

### Read Scaling Pattern

```
Application Architecture:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Write:    â”‚â”€â”€â”€â”€â”€â”€â†’ Master (R/W)
â”‚  â”‚ Redis.M   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Read:     â”‚â”€â”€â”€â”€â”€â”€â†’ Replicas (R)
â”‚  â”‚ Random or â”‚  â”‚         â”‚
â”‚  â”‚ RoundRobinâ”‚  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
                            â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Replica 1    â”‚
                    â”‚  Replica 2    â”‚
                    â”‚  Replica 3    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Writes: 1 node (master)
Reads:  N nodes (master + replicas)
â†’ Scale reads linearly!
```

### Important Considerations

**1. Eventual Consistency**
```
Time: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
Master:   [WRITE]
            â†“
Replica1:   [........APPLY] (lag: 100ms)
Replica2:   [..........APPLY] (lag: 200ms)

Read from Replica2 immediately after write?
â†’ Might get old data!
```

**2. Master Failure**
```
Without Sentinel:
Master dies â†’ Manual promotion needed
         â†’ Downtime!

With Sentinel (next section):
Master dies â†’ Auto-promote replica
         â†’ Minimal downtime!
```

**3. Replication Loop Prevention**
```
Redis prevents loops:

Master1 â†’ Replica1 â†’ Replica2 âœ… (OK: cascade)
Master1 â‡„ Master2 âŒ (PREVENTED: loop)
```

---

## ğŸ›¡ï¸ High Availability with Sentinel

**Sentinel provides automatic failover when master fails.**

### Architecture

```
Application Layer:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application connects to Sentinel      â”‚
â”‚  Sentinel tells it current master      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    Sentinel Cluster (Monitors Redis):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Sentinel 1â”‚Sentinel 2â”‚Sentinel 3â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚         â”‚          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ (monitors)
                   â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Master (R/W)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
          â†“                 â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Replica 1 â”‚      â”‚Replica 2 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How Sentinel Works

#### 1. Monitoring

```
Every 1 second:
Sentinels â”€â”€PINGâ”€â”€â†’ Master, Replicas, Other Sentinels

Every 10 seconds:
Sentinels â”€â”€INFOâ”€â”€â†’ Master, Replicas
(Discover topology changes)

Every 2 seconds:
Sentinels â”€â”€Pub/Subâ”€â”€â†’ Other Sentinels
(Share information)
```

#### 2. Failure Detection (Quorum)

```
Timeline:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’

T0: Master healthy
    All sentinels: "Master OK"

T1: Master crashes
    Sentinel 1: PING... timeout (subjectively down)
    
T2: Sentinel 1 asks others
    Sentinel 1: "Is master down?"
    Sentinel 2: "Yes, timeout for me too"
    Sentinel 3: "Yes, timeout for me too"
    
T3: Quorum reached (2 out of 3 agree)
    Master is OBJECTIVELY DOWN
    
T4: Sentinel 1 wins election to do failover
    (Sentinel with highest ID that agrees)
```

**Quorum:** Minimum sentinels that must agree master is down

```
Quorum = 2 (with 3 sentinels)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Sentinel1â”‚Sentinel2â”‚Sentinel3â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚         â”‚         â”‚
     Down      Down      Up
     
2 agree â†’ Failover starts! âœ…

Quorum = 3 (with 3 sentinels)
     Down      Down      Up
     
2 agree â†’ Not enough! âŒ
(Master stays, no failover)
```

#### 3. Automatic Failover

```
Failover Steps:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Step 1: Select new master
â””â”€â†’ Pick best replica:
    â€¢ Online & healthy
    â€¢ Low replication lag
    â€¢ High replica priority
    â€¢ Lowest runid (tiebreaker)

Step 2: Promote replica
â””â”€â†’ Send: SLAVEOF NO ONE
    Replica becomes master!

Step 3: Reconfigure other replicas
â””â”€â†’ Send to other replicas:
    SLAVEOF <new-master-ip> <new-master-port>

Step 4: Notify clients
â””â”€â†’ Publish: +switch-master event
    Applications update master address

Step 5: Monitor old master
â””â”€â†’ When old master comes back:
    Convert to replica:
    SLAVEOF <new-master-ip> <new-master-port>

Timeline:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ T0: Master down detected            â”‚
â”‚ T1: Quorum reached (+1-2 seconds)   â”‚
â”‚ T2: Replica promoted (+1 second)    â”‚
â”‚ T3: Others reconfigured (+1 second) â”‚
â”‚ Total downtime: ~3-5 seconds        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration

**sentinel.conf:**

```redis
# Monitor this master
sentinel monitor mymaster 10.0.1.1 6379 2
#                  â†‘name    â†‘ip    â†‘port â†‘quorum

# Master down after 5 seconds of no response
sentinel down-after-milliseconds mymaster 5000

# Allow 1 replica to sync at a time during failover
sentinel parallel-syncs mymaster 1

# Failover timeout (30 seconds)
sentinel failover-timeout mymaster 30000

# Notification scripts (optional)
sentinel notification-script mymaster /path/to/notify.sh
sentinel client-reconfig-script mymaster /path/to/reconfig.sh
```

**Sentinel Deployment:**

```
Minimum: 3 Sentinels (allows 1 failure)

Why odd numbers?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
3 Sentinels: Can tolerate 1 failure (quorum=2)
4 Sentinels: Can tolerate 1 failure (quorum=3)
5 Sentinels: Can tolerate 2 failures (quorum=3)

â†’ Use odd numbers! 4 is same as 3.

Placement:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âŒ Bad: All sentinels on same machine
   (Single point of failure)

âœ… Good: Sentinels on different machines
   (True high availability)

âœ… Better: Sentinels in different availability zones
   (Survive zone failure)
```

### Client Integration

**Application connects to Sentinel, not directly to Redis:**

```go
// Go example with go-redis
client := redis.NewFailoverClient(&redis.FailoverOptions{
    MasterName:    "mymaster",
    SentinelAddrs: []string{
        "sentinel1:26379",
        "sentinel2:26379", 
        "sentinel3:26379",
    },
})

// Client automatically:
// 1. Asks sentinels for current master
// 2. Connects to master
// 3. Subscribes to +switch-master events
// 4. Reconnects to new master on failover
```

### Sentinel Failure Scenarios

```
Scenario 1: One Sentinel Dies
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
3 sentinels, quorum=2
Sentinel 1 dies
â†’ Still have 2 sentinels
â†’ Can still detect failures âœ…
â†’ System operational

Scenario 2: Two Sentinels Die
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
3 sentinels, quorum=2
Sentinels 1 & 2 die
â†’ Only 1 sentinel left
â†’ Cannot reach quorum âŒ
â†’ No automatic failover
â†’ Manual intervention needed

Scenario 3: Master + Sentinel Die Together
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Master and Sentinel 1 die (same machine)
â†’ 2 sentinels left
â†’ Can still detect & failover âœ…
â†’ Importance of separate machines!

Scenario 4: Network Partition
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Sentinels can't reach master (network issue)
â†’ Sentinels think master is down
â†’ Failover happens
â†’ Problem: Master is still serving old clients!
â†’ Split-brain scenario âš ï¸

Protection:
min-replicas-to-write 1
min-replicas-max-lag 10
â†’ Master stops accepting writes if no replicas
```

---

## ğŸŒ Horizontal Scaling with Cluster

**Redis Cluster provides automatic sharding across multiple nodes.**

### Architecture

```
Redis Cluster (6 nodes):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Hash Slot Distribution                â”‚
â”‚               (16,384 slots total)                â”‚
â”‚                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Master 1   â”‚   Master 2   â”‚   Master 3   â”‚  â”‚
â”‚  â”‚  Slots 0-    â”‚ Slots 5461-  â”‚Slots 10923-  â”‚  â”‚
â”‚  â”‚   5460       â”‚  10922       â”‚  16383       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚              â”‚              â”‚          â”‚
â”‚         â†“              â†“              â†“          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Replica 1   â”‚  Replica 2   â”‚  Replica 3   â”‚  â”‚
â”‚  â”‚ (for Master1)â”‚(for Master 2)â”‚(for Master 3)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Minimum: 3 masters (recommended: 3 masters + 3 replicas)
```

### Hash Slots

Redis Cluster uses **hash slots** to determine which node owns which keys:

```
Hash Slot Algorithm:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Hash the key: HASH = CRC16(key)
2. Modulo 16384: SLOT = HASH % 16384
3. Find node: Node = slot_to_node_map[SLOT]

Example:
â”€â”€â”€â”€â”€â”€â”€â”€
Key: "user:1000"
CRC16("user:1000") = 5432
5432 % 16384 = 5432
Slot 5432 â†’ Master 1 (owns slots 0-5460)

Key: "user:2000"
CRC16("user:2000") = 8765
8765 % 16384 = 8765
Slot 8765 â†’ Master 2 (owns slots 5461-10922)
```

**Hash Tags (for multi-key operations):**

```
Problem:
MGET user:1000 user:2000
â†’ Keys might be on different nodes!
â†’ Error: CROSSSLOT

Solution - Hash Tags:
Use {tag} in key name:
MGET user:{1000}:profile user:{1000}:settings
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         Hashed
Both keys hash to same slot â†’ Same node! âœ…

Examples:
"user:{1000}:profile" â†’ Hash {1000}
"user:{1000}:settings" â†’ Hash {1000}
â†’ Both on same node, multi-key ops work!
```

### Cluster Communication

**Gossip Protocol:**

```
Every node maintains:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cluster State (in memory)           â”‚
â”‚  â€¢ All nodes (master & replica)      â”‚
â”‚  â€¢ Slot assignments                  â”‚
â”‚  â€¢ Node states (online/failed)       â”‚
â”‚  â€¢ Network topology                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Every second:
Node randomly picks a few other nodes
Sends: "Here's what I know about cluster"
Receives: "Here's what I know"
Merges information

Result: Eventually consistent cluster view
```

**Cluster Bus (Port + 10000):**

```
Client Port: 6379 (normal Redis)
Cluster Port: 16379 (cluster bus)

Purpose: Node-to-node communication
â€¢ Gossip protocol
â€¢ Failure detection
â€¢ Slot migration
â€¢ Redirect information
```

### Client Redirection

```
Scenario: Client connects to wrong node

Client             Node 1              Node 2
  â”‚                  â”‚                   â”‚
  â”‚â”€â”€GET user:2000â”€â”€â†’â”‚                   â”‚
  â”‚                  â”œâ”€ Hash â†’ Slot 8765â”‚
  â”‚                  â”œâ”€ Slot 8765 owned  â”‚
  â”‚                  â”‚   by Node 2       â”‚
  â”‚                  â”‚                   â”‚
  â”‚â†â”€MOVED 8765â”€â”€â”€â”€â”€â”€â”‚                   â”‚
  â”‚   node2:6379     â”‚                   â”‚
  â”‚                  â”‚                   â”‚
  â”‚â”€â”€â”€â”€â”€â”€â”€GET user:2000â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚
  â”‚                  â”‚                   â”‚
  â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â”€"value"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚

Client learns and caches:
Slot 8765 â†’ Node 2
(Future requests go directly to Node 2)
```

**ASK vs MOVED:**

```
MOVED: Slot permanently moved
â”€â”€â”€â”€â”€
Client: GET key
Node: -MOVED 8765 node2:6379
â†’ "Slot 8765 is now on node2, update your cache!"

ASK: Slot temporarily on another node (during migration)
â”€â”€â”€â”€
Client: GET key  
Node: -ASK 8765 node2:6379
â†’ "Slot 8765 is migrating to node2, ask there but don't cache!"
Client: ASKING (special command)
Client: GET key
Node2: Returns data
```

### Resharding (Adding/Removing Nodes)

```
Add Node 4:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Before:
Master 1: Slots 0-5460
Master 2: Slots 5461-10922  
Master 3: Slots 10923-16383

After:
Master 1: Slots 0-4095     (gave 1365 slots to Node 4)
Master 2: Slots 5461-9557  (gave 1365 slots to Node 4)
Master 3: Slots 10923-15018 (gave 1365 slots to Node 4)
Master 4: Slots 4096-5460, 9558-10922, 15019-16383

Process:
1. Add Node 4 to cluster
2. Move slots from Node 1/2/3 to Node 4
3. Slot migration:
   a. Mark slot as MIGRATING on source
   b. Mark slot as IMPORTING on target
   c. Move keys one by one (MIGRATE command)
   d. Update cluster config when done

During migration:
â€¢ Existing keys: Served from source
â€¢ New keys: Written to target
â€¢ Client sees ASK redirects
```

**Command:**

```bash
# Reshard 1000 slots from all nodes to new node
redis-cli --cluster reshard <node-ip>:6379 \
  --cluster-from all \
  --cluster-to <new-node-id> \
  --cluster-slots 1000
```

### Failover in Cluster

```
Scenario: Master 2 fails

Before:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Master 1 â”‚ Master 2 â”‚ Master 3 â”‚
â”‚ (online) â”‚  (DOWN)  â”‚ (online) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
         â”‚  Replica 2  â”‚
         â”‚  (detects)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After failover:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Master 1 â”‚Replica 2 â”‚ Master 3 â”‚
â”‚ (online) â”‚(PROMOTED)â”‚ (online) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         
         (Old Master 2 becomes replica when returns)

Failover process:
1. Replica 2 detects master down (after timeout)
2. Replica 2 asks other masters to vote
3. Masters vote for replica to promote
4. Replica 2 becomes master
5. Cluster config updated
6. Clients redirected to new master

Downtime: ~2-5 seconds
```

### Configuration

**redis.conf for Cluster:**

```redis
# Enable cluster mode
cluster-enabled yes

# Cluster config file (auto-maintained)
cluster-config-file nodes-6379.conf

# Node timeout (15 seconds)
cluster-node-timeout 15000

# Replica can failover if master fails
cluster-replica-validity-factor 10

# Require all slots assigned
cluster-require-full-coverage yes
```

**Create Cluster:**

```bash
# Start 6 Redis instances on different ports
redis-server --port 7000 --cluster-enabled yes ...
redis-server --port 7001 --cluster-enabled yes ...
redis-server --port 7002 --cluster-enabled yes ...
redis-server --port 7003 --cluster-enabled yes ...
redis-server --port 7004 --cluster-enabled yes ...
redis-server --port 7005 --cluster-enabled yes ...

# Create cluster
redis-cli --cluster create \
  127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 \
  127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \
  --cluster-replicas 1
```

### Limitations

```
âŒ Multi-key operations only work if keys on same slot
   MGET key1 key2  â†’ Error if different nodes
   Solution: Use hash tags {user}

âŒ No multi-database support
   SELECT 1 â†’ Not supported
   Cluster only uses database 0

âŒ Limited Lua script support
   Scripts can only access keys on same slot

âŒ More complex operations
   Backup: Must backup all nodes
   Monitoring: Monitor all nodes
```

### When to Use Cluster

```
âœ… Use Cluster when:
â€¢ Dataset > single server RAM
â€¢ Write throughput > single server
â€¢ Need horizontal scaling
â€¢ Can adapt app for sharding

âŒ Don't use Cluster when:
â€¢ Dataset fits in single server
â€¢ Multi-key operations critical
â€¢ Simplicity is priority
â€¢ Can scale with read replicas
```

---

## âš¡ Performance Characteristics

### Operation Complexity

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Time Complexity                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Strings:                                       â”‚
â”‚    GET, SET, INCR             O(1)              â”‚
â”‚    MGET (N keys)              O(N)              â”‚
â”‚                                                  â”‚
â”‚  Lists:                                         â”‚
â”‚    LPUSH, RPUSH, LPOP, RPOP   O(1)              â”‚
â”‚    LINDEX (by index)          O(N)              â”‚
â”‚    LRANGE (M elements)        O(N+M)            â”‚
â”‚                                                  â”‚
â”‚  Sets:                                          â”‚
â”‚    SADD, SREM, SISMEMBER      O(1)              â”‚
â”‚    SINTER (2 sets)            O(N*M)            â”‚
â”‚    SUNION (2 sets)            O(N+M)            â”‚
â”‚                                                  â”‚
â”‚  Hashes:                                        â”‚
â”‚    HGET, HSET, HDEL           O(1)              â”‚
â”‚    HGETALL                    O(N)              â”‚
â”‚                                                  â”‚
â”‚  Sorted Sets:                                   â”‚
â”‚    ZADD, ZREM                 O(log N)          â”‚
â”‚    ZSCORE                     O(1)              â”‚
â”‚    ZRANGE (M elements)        O(log N + M)      â”‚
â”‚    ZRANK                      O(log N)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Throughput

```
Single Redis instance (rough estimates):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Simple operations (GET/SET):        â”‚
â”‚    ~100,000 ops/sec                  â”‚
â”‚                                      â”‚
â”‚  With pipelining:                    â”‚
â”‚    ~1,000,000 ops/sec                â”‚
â”‚                                      â”‚
â”‚  Complex operations (SORT, LRANGE):  â”‚
â”‚    ~10,000 ops/sec                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Factors affecting throughput:
â€¢ CPU speed (single-threaded!)
â€¢ Network latency
â€¢ Command complexity
â€¢ Data size
â€¢ Persistence settings
```

### Latency

```
Typical latencies (same datacenter):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GET/SET (simple):                   â”‚
â”‚    < 1 millisecond                   â”‚
â”‚    Often < 100 microseconds          â”‚
â”‚                                      â”‚
â”‚  ZADD (sorted set):                  â”‚
â”‚    < 1 millisecond                   â”‚
â”‚                                      â”‚
â”‚  SORT (large dataset):               â”‚
â”‚    1-100 milliseconds                â”‚
â”‚                                      â”‚
â”‚  Disk fsync (AOF always):            â”‚
â”‚    1-10 milliseconds                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Sources of latency:
â€¢ Network RTT (biggest factor usually)
â€¢ Command complexity
â€¢ Memory swapping (avoid!)
â€¢ Disk I/O (persistence)
â€¢ Background operations (RDB, AOF rewrite)
```

### Monitoring Performance

```bash
# Monitor commands in real-time
redis-cli --latency
redis-cli --latency-history
redis-cli --latency-dist

# Find slow commands
CONFIG SET slowlog-log-slower-than 10000  # 10ms
SLOWLOG GET 10

# Check command stats
INFO commandstats

# Monitor operations
redis-cli MONITOR
```

---

## ğŸ­ Production Considerations

### Monitoring

**Key Metrics to Track:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memory:                                        â”‚
â”‚    â€¢ used_memory                                â”‚
â”‚    â€¢ used_memory_peak                           â”‚
â”‚    â€¢ mem_fragmentation_ratio (< 1.5 is good)    â”‚
â”‚    â€¢ evicted_keys (should be 0 ideally)         â”‚
â”‚                                                  â”‚
â”‚  Performance:                                   â”‚
â”‚    â€¢ instantaneous_ops_per_sec                  â”‚
â”‚    â€¢ latency (99th percentile)                  â”‚
â”‚    â€¢ hit_rate (keyspace_hits / total)           â”‚
â”‚                                                  â”‚
â”‚  Replication:                                   â”‚
â”‚    â€¢ connected_slaves                           â”‚
â”‚    â€¢ master_repl_offset (lag)                   â”‚
â”‚                                                  â”‚
â”‚  Persistence:                                   â”‚
â”‚    â€¢ rdb_last_save_time                         â”‚
â”‚    â€¢ aof_current_size                           â”‚
â”‚                                                  â”‚
â”‚  Errors:                                        â”‚
â”‚    â€¢ rejected_connections                       â”‚
â”‚    â€¢ keyspace_misses                            â”‚
â”‚    â€¢ sync_full (should be rare)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Get metrics:**

```bash
redis-cli INFO all
redis-cli INFO memory
redis-cli INFO stats
redis-cli INFO replication
```

### Security

```redis
# 1. Require password
requirepass <strong-password>

# 2. Bind to specific interface
bind 10.0.1.1

# 3. Rename dangerous commands
rename-command FLUSHALL ""
rename-command FLUSHDB ""
rename-command CONFIG "CONFIG-8f3a9b2c"

# 4. Use ACLs (Redis 6+)
ACL SETUSER alice on >password ~cache* +get +set

# 5. Enable TLS (Redis 6+)
tls-port 6380
tls-cert-file /path/to/redis.crt
tls-key-file /path/to/redis.key

# 6. Protected mode (default in 3.2+)
protected-mode yes
```

### Capacity Planning

```
Formula:
â”€â”€â”€â”€â”€â”€â”€â”€
Total Memory = (Dataset Size) Ã— (Replication Factor) Ã— (Overhead)

Example:
â”€â”€â”€â”€â”€â”€â”€â”€
Dataset: 10GB actual data
Replication: 2 (1 master + 1 replica)
Overhead: 1.3 (30% for fragmentation, metadata, buffers)

Total: 10GB Ã— 2 Ã— 1.3 = 26GB RAM needed

Buffer:
â”€â”€â”€â”€â”€â”€â”€â”€
Add 20-30% buffer for:
â€¢ Fragmentation spikes
â€¢ RDB fork (copy-on-write)
â€¢ AOF rewrite buffers
â€¢ Growth

Final: 26GB Ã— 1.25 = ~33GB RAM
```

### Backup Strategy

```bash
# RDB Backups
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Trigger manual save
BGSAVE

# Copy RDB file
cp /var/lib/redis/dump.rdb /backup/dump-$(date +%Y%m%d).rdb

# Automate
0 2 * * * redis-cli BGSAVE && \
  sleep 60 && \
  cp /var/lib/redis/dump.rdb /backup/dump-$(date +\%Y\%m\%d).rdb

# AOF Backups
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Trigger rewrite
BGREWRITEAOF

# Copy AOF file
cp /var/lib/redis/appendonly.aof /backup/appendonly-$(date +%Y%m%d).aof

# Test restoration:
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Stop Redis
2. Copy backup to data directory
3. Start Redis
4. Verify: DBSIZE, spot check keys
```

### Common Issues

**1. Memory Fragmentation**

```bash
# Check fragmentation
redis-cli INFO memory | grep mem_fragmentation_ratio

# If > 1.5:
# Option 1: Restart Redis (clears fragmentation)
# Option 2: CONFIG SET activedefrag yes (Redis 4.0+)
```

**2. Slow Commands**

```bash
# Find culprits
SLOWLOG GET 10

# Common issues:
# - KEYS * (use SCAN instead)
# - SORT on large sets
# - ZRANGE on huge sorted sets
# - Blocking commands in pipeline
```

**3. Memory Issues**

```bash
# Out of memory errors

# Check:
redis-cli INFO memory

# Solutions:
# 1. Increase maxmemory
# 2. Enable eviction
# 3. Add more nodes (cluster)
# 4. Delete old data
# 5. Optimize data structures
```

**4. Replication Lag**

```bash
# Monitor lag
redis-cli INFO replication | grep lag

# Causes:
# - Network issues
# - Master overloaded
# - Slow replica disk
# - Large writes

# Solutions:
# - Reduce write load
# - Upgrade network
# - Disable persistence on replica
# - Scale horizontally
```

---

## ğŸ“ Summary

### Redis in a Nutshell

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis = In-Memory + Data Structures + Simple   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  Speed:        Sub-millisecond latency          â”‚
â”‚  Throughput:   100k+ ops/sec per node           â”‚
â”‚  Threading:    Single-threaded (simple!)        â”‚
â”‚  Persistence:  RDB (snapshots) or AOF (log)     â”‚
â”‚  HA:           Replication + Sentinel           â”‚
â”‚  Scaling:      Cluster (sharding)               â”‚
â”‚                                                  â”‚
â”‚  Use for:                                       â”‚
â”‚    â€¢ Caching                                    â”‚
â”‚    â€¢ Session storage                            â”‚
â”‚    â€¢ Real-time analytics                        â”‚
â”‚    â€¢ Leaderboards                               â”‚
â”‚    â€¢ Rate limiting                              â”‚
â”‚    â€¢ Pub/Sub messaging                          â”‚
â”‚                                                  â”‚
â”‚  Don't use for:                                 â”‚
â”‚    â€¢ Complex queries                            â”‚
â”‚    â€¢ Large datasets (> RAM)                     â”‚
â”‚    â€¢ ACID transactions across entities          â”‚
â”‚    â€¢ Primary durable storage                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Decision Trees

**Persistence:**
```
Can lose data? â†’ YES â†’ How much?
                          â”œâ”€ 1-5 min â†’ RDB
                          â””â”€ < 1 sec â†’ AOF (everysec)
               â†’ NO  â†’ AOF (always) or Hybrid
```

**High Availability:**
```
Need automatic failover? â†’ YES â†’ Sentinel
                        â†’ NO  â†’ Manual or Replication only
```

**Scaling:**
```
Dataset > RAM? â†’ YES â†’ Cluster
               â†’ NO  â†’ Single instance or Replicas (read scaling)
```

---

## ğŸ“š Further Reading

- [Redis Official Documentation](https://redis.io/documentation)
- [Redis Internals](https://redis.io/topics/internals)
- [Redis Persistence](https://redis.io/topics/persistence)
- [Redis Replication](https://redis.io/topics/replication)
- [Redis Sentinel](https://redis.io/topics/sentinel)
- [Redis Cluster](https://redis.io/topics/cluster-tutorial)

---

**Now you understand Redis from the inside out!** ğŸ‰

Time to apply this knowledge in the hands-on examples and build something real.

